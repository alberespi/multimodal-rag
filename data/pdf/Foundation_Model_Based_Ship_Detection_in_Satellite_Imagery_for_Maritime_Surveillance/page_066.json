{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 66,
  "text": "50 CHAPTER 6. CONCLUSIONS & FUTURE WORK\nCollectively, these findings validate the central hypothesis: a self-supervised\nfoundation model can deliver accurate, label-efficient, and operationally\nviable ship detection on PlanetScope imagery , paving the way for scalable\nmaritime-surveillance services.\n6.2 Future Work\nBuilding on the strengths and limitations identified in Chapter 5, six priority lines of\nwork are proposed. Each addresses a concrete limitation of the current prototype while\nremaining realistic within the MARVISION roadmap.\n1. Domain expansion to new seas\nIntegrate PlanetScope imagery from the Atlantic and Indo-Pacific, followed by\nlight fine–tuning (20-30 new scenes). This will quantify geographic generalization\nand reduce the Western-Mediterranean bias seen in Section 5.3.\n2. Synthetic wakes and rotation augmentations\nExtend the augmentation pipeline with procedural wake overlays, random rota-\ntions and specular noise. The goal is to cut false positives on wakes/coastlines\nand improve recall on oblique vessels.\n3. Balanced or focal IoU loss\nReplace the BCE term with a class-balanced focal component to penalize over-\nsegmentation and boost minority pixels, then re-evaluate instance IoU on the\ncurrent test split.\n4. Multi-resolution fusion (PlanetScope + Sentinel-2)\nDevelop a dual–branch encoder that ingests co–registered PlanetScope ( ∼3 m\nGSD) and Sentinel–2 MSI (10 m GSD) patches. The goal is to combine Plan-\netScope’s fine spatial detail with Sentinel-2’s broader context, yielding scale–robust\ndetection while remaining within the optical domain. This step is facilitated by\nthe six-band PlanetScope subset already employed in this thesis, which was se-\nlected for interoperability with the corresponding Sentinel-2 bands.\n5. Continual learning pipeline\nDeploy an automated monthly fine-tuning loop that ingests new analyst labels,\nusing rehearsal buffers or elastic weight consolidation to avoid catastrophic for-\ngetting.\n6. Model compression and ONNX quantization\nQuantize the 61 M-parameter network to INT8 and prune redundant channels,\ntargeting a footprint <90 MB and real-time inference on edge hardware or future\non-board processing units.",
  "image": "page_066.png"
}