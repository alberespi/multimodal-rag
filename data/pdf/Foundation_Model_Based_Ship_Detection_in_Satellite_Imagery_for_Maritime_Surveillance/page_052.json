{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 52,
  "text": "36 CHAPTER 4. EXPERIMENTAL SETUP AND RESULTS\n4.2.1 Training Progress and Loss Curves for Fine-Tuning\nFine-tuning was run for 200 epochs without early-stopping, using Adam ( LR = 1 ×\n10−1, β1 = 0.9, β2 = 0.999) and a batch size of 16. Data augmentations were intention-\nally disabled to isolate the impact of loss-function choice. The IoU metrics reported\nlater use an IoU threshold of 0.20and min size = 2 pxso that only vessels covering\nat least two pixels are counted as valid instances.\nFigure 4.4: Training and validation loss (log scale) during fine-tuning with\nBCE IoU Loss. The best validation loss occurs at epoch 131, which is used as the\nreference checkpoint in subsequent evaluations.\nFigure 4.4 plots the training and validation loss (log-scale) for the BCE IoU Loss\nrun. After an initial rapid drop during the first 30 epochs, both curves descend steadily,\nwith the validation loss following the training curve closely until ≈ epoch 100. Be-\nyond that point the curves separate moderately: the training loss continues to decline,\nreaching 0.402 at epoch 200, while the validation loss stabilizes around 0.726.The\nminimum validation loss (0.675) occurs at epoch 131 , which we mark as the\nbest checkpoint for quantitative evaluation in Sections 4.2.2 and 4.2.3. Although the\nabsolute loss values remain relatively high compared with the self-supervised phase,\nqualitative inspection (Section 4.2.4) and quantitative IoU scores (Section 4.2.2) reveal\nthat the model at epoch 131 produces accurate masks with few false alarms. This il-\nlustrates an important practical observation: for highly-imbalanced segmentation\nproblems, raw BCE-based losses are poorly correlated with IoU , hence we\nprioritize IoU and F1 when selecting the best checkpoint.",
  "image": "page_052.png"
}