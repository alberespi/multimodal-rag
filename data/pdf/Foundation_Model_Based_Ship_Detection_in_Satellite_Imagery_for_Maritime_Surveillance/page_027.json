{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 27,
  "text": "2.2. COMPARATIVE ANALYSIS 11\nthe same statistical threshold logic anywhere. This can be a strength (no risk of\noverfitting to a dataset), but in practice these methods need manual parameter\ntweaking for each new condition (sea clutter statistics vary, etc.), so they are\nnot automatically adaptive. Supervised deep learning detectors have notorious\ngeneralization issues when applied to unseen domains: a network trained on one\nsatellite or region often sees performance drop on another due to differences in\nimage resolution, noise or vessel appearance [9]. This key concern in maritime\nmonitoring, since one may need the model to work globally. Techniques like do-\nmain adaptation and augmentation help, but they require effort. Adaptability\nis related - how easily a method can be adapted or fine-tuned with minimal la-\nbeled samples. A few-shot fine-tuning (or even zero-shot with the right prompt,\nin the case of vision-language models) can quickly adapt a foundation model to a\nnew scenario (e.g., fine-tuning on just a handful of SAR images to detect ships in\nSAR after being pre-trained on optical images). Standard deep models can also\nbe adapted, but with more labeled data usually. Classical methods are the least\nadaptable in an automated sense; adapting them means manually recalibrating\nparameters.\n• Scalability and deployment Feasibility: Scalability considers both the ease\nof deploying the model in real operational systems and how performance scales\nwith large data. Classical methods are extremely easy to deploy - they run on\nbasic hardware and have transparent mechanisms. They scale linearly with im-\nage size and number of images and can be parallelized over large image archives\nwithout intensive computation infrastructure. This is why even today, simple\nthreshold-based detectors are sometimes used for initial scan of massive satel-\nlite archives. Deep learning methods require more complex deployment: a GPU\nserver or cloud service is typically needed to process images in bulk, especially\nif using high-resolution imagery. However, modern object detectors can be pack-\naged in lightweight forms (e.g., as ONNX models) [46] and accelerated by AI\nchips, making deployment on satellites or aircraft increasingly feasible. For in-\nstance, companies have demonstrated on-board ship detection on micro-satellites\nusing compact neural networks [47]. Real-time alerting is achievable with one-\nstage models given sufficient hardware. Foundation models, if extremely large\n(like a very deep transformer), might be impractical to run on the edge, but one\ncan often use a distilled or smaller version for deployment. Moreover, founda-\ntion models can be shared as a common resource (e.g., a cloud API providing\na pre-trained model that can be fine-tuned for a client’s data). This centralizes\nthe heavy computation and lets many users benefit from the same core model,\nIn terms of scaling to many targets or wide areas , deep learning models have an\nadvantage of maintaining high accuracy even as scene complexity grows (they\ncan handle many instances in one image). Traditional methods might trigger\nmany false alarms in busy scenes (e.g., a harbor with dozens of closely spaced\nvessels). In such scenarios, learning-based model that use context and learned\nfeatures handle dense targets better.\nOverall, the comparative landscape shows that deep learning with transfer\nlearning currently offers the best accuracy, whileclassical methods win in simplicity\nand speed. Foundation model approaches strive to combine the best of both\n- high accuracy and generalization, with less training data burden - at the cost of",
  "image": "page_027.png"
}