{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 28,
  "text": "12 CHAPTER 2. RELATED WORK\ninitial complexity and resources for pre-training. As computing hardware continues\nto improve and large models become more accessible, it is expected that foundation-\nmodel-powered detectors will be increasingly favored for their superior robustness in\nreal-world maritime surveillance.\nApproach Detection Accuracy Computational Effi-\nciency\nGeneralization &\nAdaptability\nScalability & De-\nployment\nTraditional\n(Rule-based)\ne.g., CFAR\nthresholding\nModerate in simple\nscenarios; struggles\nwith small or low-\ncontrast vessels.\nHigh false-alarm risk\nin complex back-\ngrounds [9].\nVery high efficiency:\nFast runtime, minimal\nresource needs (can run\non CPU).\nSuitable for real-time\nscanning of large areas.\nRelies on fixed statisti-\ncal models - not data-\ndriven.\nRequires manual re-\ntuning for different sea\nstates or sensors (lim-\nited adaptability).\nEasy to deploy on\nany platform (even\non-board satellites)\ndue to low resource\nusage.\nScales linearly with\nimage size; but may\nproduce many false\ndetections in crowded\nscenes.\nDeep Learning\n(Supervised)\nYOLO, Faster\nR-CNN\nState-of-the-art ac-\ncuracy:\nHigh precision and re-\ncall (often Â¿90% on\nbenchmarks) [7].\nDetects small and large\nvessels with learned\nfeatures, vastly outper-\nforms classical meth-\nods in challenging con-\nditions.\nModerate effi-\nciency:\nRequires GPU or\nneural accelerator for\nreal-time performance.\nOne-stage models\n(YOLO) achieve near\nreal-time inference [7];\ntwo-stage models are\nslower.\nComputational cost\ngrows with size and\nmodel complexity.\nGood generalization if\ntraining data covers\nthe scenario.\nOtherwise, perfor-\nmance can drop on\nunseen conditions [9].\nAdaptable through re-\ntraining or fine-tuning,\nbut needs labeled data.\nSome robustness\ngained via data\naugmentation and\nregularization.\nDeployment is feasible\non servers or edge\ndevices with AI chips.\nModels must be quan-\ntized/optimized for\nedge use.\nScalability depends on\ncomputing infrastruc-\nture; processing large\nimage volumes is costly\nbut parallelizable.\nWidely adopted in\noperational systems\nwith cloud support.\nFoundation\nModel-Based\ne.g., Pre-\ntrained/self-\nsupervised\nbackbone\nHigh accuracy even\nwith limited new la-\nbels:\nPre-training on diverse\ndata yields robust fea-\ntures, improving detec-\ntion of difficult tar-\ngets (fewer missed ves-\nsels) [8].\nApproaches supervised\nbaseline performance,\nsometimes exceeding it\nin low-data regimes.\nHigh training cost ,\nbut inference cost\nvaries:\nPre-training (unsuper-\nvised) is computation-\nally intensive (done of-\nfline).\nInference can be on\npar with standard deep\nmodels if using a simi-\nlar architecture (e.g., a\nResNet50 backbone).\nVery large models may\nbe slower, but tech-\nniques like model dis-\ntillation can alleviate\nthis.\nStrong generaliza-\ntion:\nBroad pre-training\nconfers resistance to\ndistribution shifts\n(sensor, location) [8].\nReadily adaptable via\nfine-tuning or even\nzero-shot/prompt-\nbased methods.\nCan quickly learn new\nvessel types or con-\nditions with minimal\nadditional data.\nRequires access to pre-\ntrained model (often\nlarge).\nDeployment of a huge\nmodel on the edge\nis challenging, but\nfeasible via cloud or\nby using compressed\nversions.\nScales well in the sense\nthat one foundation\nmodel can serve many\ntasks/users.\nAs data grows, the\nsame model can be\ncontinually refined\nrather than training\nseparate models for\neach new dataset.\nTable 2.2: Comparison of vessel detection approaches.\n2.3 Evaluation Frameworks\n2.3.1 Datasets\nA variety of datasets and benchmarks have been established for training and evaluating\nvessel detection algorithms. These include both synthetic aperture radar datasets and\noptical imagery datasets, each with its own characteristics:",
  "image": "page_028.png"
}