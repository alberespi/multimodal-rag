{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 47,
  "text": "Chapter 4\nExperimental Setup and Results\nThis chapter presents the experimental results of the proposed foundation model-based\napproach for ship detection in satellite imagery. The results are organized into two\nphases reflecting the two-stage methodology. Phase 1 covers the self-supervised pre-\ntraining of the foundation model on unlabeled PlanetScope imagery, while Phase 2\ndetails the fine-tuning of this pretrained model for the downstream task of ship detec-\ntion. Both quantitative and qualitative evaluations are provided, alongside compar-\nisons of various loss functions and training configurations. Key performance metrics\n– including pixel-wise precision, recall, F1-score, and Intersection-over-Union (IoU) –\nare reported, as well as instance-wise precision and recall to assess how well individual\nships are detected. The chapter also includes training loss curves and confusion ma-\ntrices to give a comprehensive view of model performance. Cross-references to figures,\ntables, and earlier sections are used to contextualize and highlight significant findings.\n4.1 Self-Supervised Pretraining on Unlabeled Im-\nagery\nThis section evaluates the outcomes of the self-supervised pretraining stage (as de-\nscribed in Chapter 3), where the foundation model was trained on 128×128 PlanetScope\nmultispectral image patches without labels. The aim of this phase is to learn gener-\nalizable representations through an image reconstruction task. Two alternative loss\nfunctions – Mean Squared Error ( MSELoss) and Binary Cross-Entropy ( BCELoss)\n– were experimented with during pretraining. The subsections below present the train-\ning convergence behavior under each loss, compare the quantitative reconstruction\nperformance, and provide qualitative examples of reconstructed images. We highlight\nwhich loss function yielded better feature learning as evidenced by lower reconstruction\nerror and higher visual fidelity, laying the groundwork for the fine-tuning in Phase 2.\n4.1.1 Training Convergence and Loss Curve Comparison\nTo evaluate the learning dynamics of the self-supervised pretraining stage, we mon-\nitored the training and validation loss curves over the course of 500 epochs for two\nalternative loss functions: Binary Cross-Entropy ( BCELoss) and Mean Squared Er-\nror (MSELoss). Both models were trained on PlanetScope image patches using the\nmasked reconstruction task described in Chapter 3. The objective was to determine\n31",
  "image": "page_047.png"
}