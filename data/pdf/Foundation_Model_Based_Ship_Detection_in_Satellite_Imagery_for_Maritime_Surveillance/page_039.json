{
  "source": "Foundation_Model_Based_Ship_Detection_in_Satellite_Imagery_for_Maritime_Surveillance.pdf",
  "page": 39,
  "text": "3.3. FINE-TUNING FOR SHIP DETECTION 23\nFigure 3.2: Generic U-Net encoder-decoder architecture. The contracting path (left)\nsuccessively downsamples the input tile by max-pooling, while the expanding path\n(right) upsamples and concatenates feature maps via skip connections to reconstruct\na full–resolution segmentation mask [1].\nparticular, we used common geometric augmentations such as random rotations (e.g.,\n90◦ increments or small arbitrary angles) and horizontal/vertical flips, a standard regu-\nlarization technique in computer vision [65]. Each training patch had a random chance\nof being rotated or flipped before masking and feeding it to the network, effectively\nincreasing the diversity of views seen during pretraining. These augmentations help\nthe encoder learn invariant feature representations (for example, a ship looks like a\nship regardless of orientation), which is beneficial for downstream detection. We note\nthat no color or brightness augmentations were applied (since the focus was on geomet-\nric invariances), and that all augmentations were applied only during the foundation\nmodel training.\nTraining of the foundation model was carried out using a reconstruction loss com-\nputed only on the masked-out pixels (the model’s task being to predict those missing\npixel values). We employed a mean squared error (MSE) loss between the decoder\noutput and the ground truth pixels in the masked regions. The model was optimized\nusing the Adam optimizer, and we trained for several hundred epochs until convergence\n(details of hyperparameters are provided in Section 3.5.2). Through this unsupervised\ntraining, the encoder gradually learned to capture essential scene content in its latent\nfeatures in order to fill in missing areas – effectively learning a rich representation of\nPlanetScope imagery without any manual annotations.\n(Note: Details of the network architecture – number of layers, feature dimensions,\netc. – are kept at a high level for confidentiality. The key point is the encoder-decoder\ndesign and the masked reconstruction learning scheme, which are general techniques in\ncurrent deep learning research.)\n3.3 Fine-Tuning for Ship Detection\nAfter pretraining, the model was adapted and fine-tuned for the specific task of ship seg-\nmentation in PlanetScope images. We leveraged the same U-Net architecture described\nin Section 3.2.1, using the pretrained encoder as the backbone for feature extraction.\nThe decoder for this segmentation phase was newly initialized (while sharing the same",
  "image": "page_039.png"
}